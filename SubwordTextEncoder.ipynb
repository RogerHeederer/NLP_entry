{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SubwordTextEncoder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZ3DzU+h57U+ofXrQTdmOs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RogerHeederer/NLP_entry/blob/master/SubwordTextEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMtEq4Vrzwls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import urllib.request\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt1YTS9A0NoH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc2f0603-c8a0-48e4-c6c4-b9487c8c9dde"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"IMDb_Reviews.csv\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('IMDb_Reviews.csv', <http.client.HTTPMessage at 0x7f10b1c7bac8>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wgo-YbzU0QIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('IMDb_Reviews.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rq-zo8p0TSK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "db7b5939-5156-4828-a685-cc5f730c9bcb"
      },
      "source": [
        "train_df['review']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        My family and I normally do not watch local mo...\n",
              "1        Believe it or not, this was at one time the wo...\n",
              "2        After some internet surfing, I found the \"Home...\n",
              "3        One of the most unheralded great works of anim...\n",
              "4        It was the Sixties, and anyone with long hair ...\n",
              "                               ...                        \n",
              "49995    the people who came up with this are SICK AND ...\n",
              "49996    The script is so so laughable... this in turn,...\n",
              "49997    \"So there's this bride, you see, and she gets ...\n",
              "49998    Your mind will not be satisfied by this nobud...\n",
              "49999    The chaser's war on everything is a weekly sho...\n",
              "Name: review, Length: 50000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wsvaIvr0YYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(train_df['review'], target_vocab_size=2**13)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMQMfAZB0rXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "34904df2-ac7d-4c4a-837d-be9c0faf29a5"
      },
      "source": [
        "print(tokenizer.subwords[:100])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the_', ', ', '. ', 'a_', 'and_', 'of_', 'to_', 's_', 'is_', 'br', 'in_', 'I_', 'that_', 'this_', 'it_', ' /><', ' />', 'was_', 'The_', 't_', 'as_', 'with_', 'for_', '.<', 'on_', 'but_', 'movie_', 'are_', ' (', 'have_', 'his_', 'film_', 'not_', 'be_', 'you_', 'ing_', ' \"', 'ed_', 'it', 'd_', 'an_', 'at_', 'by_', 'he_', 'one_', 'who_', 'from_', 'y_', 'or_', 'e_', 'like_', 'all_', '\" ', 'they_', 'so_', 'just_', 'has_', ') ', 'about_', 'her_', 'out_', 'This_', 'some_', 'movie', 'ly_', 'film', 'very_', 'more_', 'It_', 'what_', 'would_', 'when_', 'if_', 'good_', 'up_', 'which_', 'their_', 'only_', 'even_', 'my_', 'really_', 'had_', 'can_', 'no_', 'were_', 'see_', '? ', 'she_', 'than_', '! ', 'there_', 'been_', 'get_', 'into_', 'will_', ' - ', 'much_', 'n_', 'because_', 'ing']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN2_s61m1sKr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6eb5e697-9370-4f4e-f943-27729a7b7cbb"
      },
      "source": [
        "print(train_df['review'][20])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pretty bad PRC cheapie which I rarely bother to watch over again, and it's no wonder -- it's slow and creaky and dull as a butter knife. Mad doctor George Zucco is at it again, turning a dimwitted farmhand in overalls (Glenn Strange) into a wolf-man. Unfortunately, the makeup is virtually non-existent, consisting only of a beard and dimestore fangs for the most part. If it were not for Zucco and Strange's presence, along with the cute Anne Nagel, this would be completely unwatchable. Strange, who would go on to play Frankenstein's monster for Unuiversal in two years, does a Lenny impression from \"Of Mice and Men\", it seems.<br /><br />*1/2 (of Four)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x-JVCP21wao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "97b57764-b608-42d8-ac24-5feeb63d6b44"
      },
      "source": [
        "print('Tokenized sample question: {}'.format(tokenizer.encode(train_df['review'][20])))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized sample question: [1590, 4162, 132, 7107, 1892, 2983, 578, 76, 12, 4632, 3422, 7, 160, 175, 372, 2, 5, 39, 8051, 8, 84, 2652, 497, 39, 8051, 8, 1374, 5, 3461, 2012, 48, 5, 2263, 21, 4, 2992, 127, 4729, 711, 3, 1391, 8044, 3557, 1277, 8102, 2154, 5681, 9, 42, 15, 372, 2, 3773, 4, 3502, 2308, 467, 4890, 1503, 11, 3347, 1419, 8127, 29, 5539, 98, 6099, 58, 94, 4, 1388, 4230, 8057, 213, 3, 1966, 2, 1, 6700, 8044, 9, 7069, 716, 8057, 6600, 2, 4102, 36, 78, 6, 4, 1865, 40, 5, 3502, 1043, 1645, 8044, 1000, 1813, 23, 1, 105, 1128, 3, 156, 15, 85, 33, 23, 8102, 2154, 5681, 5, 6099, 8051, 8, 7271, 1055, 2, 534, 22, 1, 3046, 5214, 810, 634, 8120, 2, 14, 71, 34, 436, 3311, 5447, 783, 3, 6099, 2, 46, 71, 193, 25, 7, 428, 2274, 2260, 6487, 8051, 8, 2149, 23, 1138, 4117, 6023, 163, 11, 148, 735, 2, 164, 4, 5277, 921, 3395, 1262, 37, 639, 1349, 349, 5, 2460, 328, 15, 5349, 8127, 24, 10, 16, 10, 17, 8054, 8061, 8059, 8062, 29, 6, 6607, 8126, 8053]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJjWK76k2A1Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ca072557-0554-400c-f0e5-21e45f408aef"
      },
      "source": [
        "# train_df에 존재하는 문장 중 일부를 발췌\n",
        "sample_string = \"It's mind-blowing to me that this film was even made.\"\n",
        "\n",
        "# 인코딩한 결과를 tokenized_string에 저장\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
        "\n",
        "# 이를 다시 디코딩\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print ('기존 문장: {}'.format(original_string))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정수 인코딩 후의 문장 [137, 8051, 8, 910, 8057, 2169, 36, 7, 103, 13, 14, 32, 18, 79, 681, 8058]\n",
            "기존 문장: It's mind-blowing to me that this film was even made.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyLFQJk82ccE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a082b175-9647-4420-aec1-11bf073131ec"
      },
      "source": [
        "print('단어 집합의 크기 : ', tokenizer.vocab_size)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 :  8268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdXTy5DB2jEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "f4eda1b9-384a-4eaf-8e9b-9e64e445ba37"
      },
      "source": [
        "for ts in tokenized_string:\n",
        "  print ('{} ---> {}'.format(ts, tokenizer.decode([ts])))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "137 ---> It\n",
            "8051 ---> '\n",
            "8 ---> s \n",
            "910 ---> mind\n",
            "8057 ---> -\n",
            "2169 ---> blow\n",
            "36 ---> ing \n",
            "7 ---> to \n",
            "103 ---> me \n",
            "13 ---> that \n",
            "14 ---> this \n",
            "32 ---> film \n",
            "18 ---> was \n",
            "79 ---> even \n",
            "681 ---> made\n",
            "8058 ---> .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXWn_Tx-2yke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ae30468d-488d-4845-d76a-676d8d29888b"
      },
      "source": [
        "# 앞서 실습한 문장에 even 뒤에 임의로 xyz 추가\n",
        "sample_string = \"It's mind-blowing to me that this film was evenxyz made.\"\n",
        "\n",
        "# 인코딩한 결과를 tokenized_string에 저장\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
        "\n",
        "# 이를 다시 디코딩\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print ('기존 문장: {}'.format(original_string))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정수 인코딩 후의 문장 [137, 8051, 8, 910, 8057, 2169, 36, 7, 103, 13, 14, 32, 18, 7974, 8132, 8133, 997, 681, 8058]\n",
            "기존 문장: It's mind-blowing to me that this film was evenxyz made.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5TQXv5d3-KS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "f8df6097-4fef-45eb-e1c5-912647adbca7"
      },
      "source": [
        "for ts in tokenized_string:\n",
        "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))\n",
        "  #evenxyz -> even / x/ y/ z 로 분리"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "137 ----> It\n",
            "8051 ----> '\n",
            "8 ----> s \n",
            "910 ----> mind\n",
            "8057 ----> -\n",
            "2169 ----> blow\n",
            "36 ----> ing \n",
            "7 ----> to \n",
            "103 ----> me \n",
            "13 ----> that \n",
            "14 ----> this \n",
            "32 ----> film \n",
            "18 ----> was \n",
            "7974 ----> even\n",
            "8132 ----> x\n",
            "8133 ----> y\n",
            "997 ----> z \n",
            "681 ----> made\n",
            "8058 ----> .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auha1yHi594_",
        "colab_type": "text"
      },
      "source": [
        "##네이버 영화 리뷰 토큰화하기##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Aaz3wR4CtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import urllib.request"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHlgTmnH6HO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b66bfe9-514f-462e-b430-b90f966c4600"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings_train.txt', <http.client.HTTPMessage at 0x7f10a4458a20>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrzm1q9s6J-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_table('ratings_train.txt')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe1Wq4Yl6PkS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9246335e-ec77-4e50-93e7-b945d10dcaa8"
      },
      "source": [
        "print(train_data.isnull().sum())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id          0\n",
            "document    5\n",
            "label       0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWKA65WA6Stq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6183fa3-4517-418e-c115-45b85b55cf24"
      },
      "source": [
        "train_data = train_data.dropna(how = 'any')\n",
        "print(train_data.isnull().values.any())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW8gY9Z26det",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    train_data['document'], target_vocab_size=2**13\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiWkHKeI68mD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "51300e46-8d93-475a-dfe1-6a0ba83d7fd1"
      },
      "source": [
        "print(tokenizer.subwords[:100])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['. ', '..', '영화', '이_', '...', '의_', '는_', '도_', '다', ', ', '을_', '고_', '은_', '가_', '에_', '.. ', '한_', '너무_', '정말_', '를_', '고', '게_', '영화_', '지', '... ', '진짜_', '이', '다_', '요', '만_', '? ', '과_', '나', '가', '서_', '지_', '로_', '으로_', '아', '어', '....', '음', '한', '수_', '와_', '도', '네', '그냥_', '나_', '더_', '왜_', '이런_', '면_', '기', '하고_', '보고_', '하는_', '서', '좀_', '리', '자', '스', '안', '! ', '에서_', '영화를_', '미', 'ㅋㅋ', '네요', '시', '주', '라', '는', '오', '없는_', '에', '해', '사', '!!', '영화는_', '마', '잘_', '수', '영화가_', '만', '본_', '로', '그_', '지만_', '대', '은', '비', '의', '일', '개', '있는_', '없다', '함', '구', '하']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWSM1h298Gxu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "27757eca-d02a-4738-f9e8-c974f95c4150"
      },
      "source": [
        "print('Tokenized sample question: {}'.format(tokenizer.encode(train_data['document'][20])))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized sample question: [669, 4700, 17, 1749, 8, 96, 131, 1, 48, 2239, 4, 7466, 32, 1274, 2655, 7, 80, 749, 1254]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nLiRoF38wct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_string = train_data['document'][21]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSljSNDxRC3K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2f8c3b6-946e-490c-b389-09f7ec874614"
      },
      "source": [
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print('정수 인코딩 후의 문장 {}'.format(tokenized_string))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정수 인코딩 후의 문장 [570, 892, 36, 584, 159, 7091, 201]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0jhhVkRRUCl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b69b31dc-09df-4411-8096-21f1da63bdb7"
      },
      "source": [
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print('기존 문장: {}'.format(original_string))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "기존 문장: 보면서 웃지 않는 건 불가능하다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfWqaAITRbL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cba074c0-3e8f-4e28-aeb6-6a59a5210dba"
      },
      "source": [
        "#기존 훈련 데이터에 없는 워드들 추가해서 테스트\n",
        "sample_string = '오 ㅋㅋ 이 영화 핵 재밌네 깔깔'\n",
        "\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print('정수 인코딩 후의 문장 {}'.format(tokenized_string))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정수 인코딩 후의 문장 [1763, 227, 4, 23, 2750, 8030, 2845, 8030, 1701, 1701]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN5o4XrER5gU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e8035fc-25da-4717-e8b6-dda11e25599c"
      },
      "source": [
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print('기존 문장: {}'.format(original_string))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "기존 문장: 오 ㅋㅋ 이 영화 핵 재밌네 깔깔\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dmgWbR4SBEZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e8442199-7a07-477b-f8b5-dcf67e453ed3"
      },
      "source": [
        "for ts in tokenized_string:\n",
        "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1763 ----> 오 \n",
            "227 ----> ㅋㅋ \n",
            "4 ----> 이 \n",
            "23 ----> 영화 \n",
            "2750 ----> 핵\n",
            "8030 ---->  \n",
            "2845 ----> 재밌네\n",
            "8030 ---->  \n",
            "1701 ----> 깔\n",
            "1701 ----> 깔\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HGKWxY7SSHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}